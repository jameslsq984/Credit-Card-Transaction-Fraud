{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has a wide variety of modeling algorithms for a binary classification problem. It reads a file creatd from a feaature selection process that has a reasonably small number of good variables. We can explore # ionput variables, model algorithms and tune model hyperparameters. ASt the end we can select our favorite algorithm, run it again and build the final model performace score percentile tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as XGBClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96397, 12)\n",
      "CPU times: user 92.8 ms, sys: 38.3 ms, total: 131 ms\n",
      "Wall time: 138 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_zip3_total_7</th>\n",
       "      <th>card_state_max_60</th>\n",
       "      <th>card_state_max_14</th>\n",
       "      <th>card_merch_total_30</th>\n",
       "      <th>Merchdesc_Zip_avg_1</th>\n",
       "      <th>card_zip3_total_1</th>\n",
       "      <th>Merchdesc_Zip_max_1</th>\n",
       "      <th>Merchnum_desc_State_avg_7</th>\n",
       "      <th>Merchnum_desc_Zip_avg_7</th>\n",
       "      <th>Card_Merchnum_State_total_30</th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   card_zip3_total_7  card_state_max_60  card_state_max_14  \\\n",
       "0               3.62               3.62               3.62   \n",
       "1              31.42              31.42              31.42   \n",
       "2             178.49             178.49             178.49   \n",
       "3               3.62               3.62               3.62   \n",
       "4               7.24               3.62               3.62   \n",
       "\n",
       "   card_merch_total_30  Merchdesc_Zip_avg_1  card_zip3_total_1  \\\n",
       "0                 3.62                 3.62               3.62   \n",
       "1                31.42                31.42              31.42   \n",
       "2               178.49               178.49             178.49   \n",
       "3                 3.62                 3.62               3.62   \n",
       "4                 7.24                 3.62               7.24   \n",
       "\n",
       "   Merchdesc_Zip_max_1  Merchnum_desc_State_avg_7  Merchnum_desc_Zip_avg_7  \\\n",
       "0                 3.62                       3.62                     3.62   \n",
       "1                31.42                      31.42                    31.42   \n",
       "2               178.49                     178.49                   178.49   \n",
       "3                 3.62                       3.62                     3.62   \n",
       "4                 3.62                       3.62                     3.62   \n",
       "\n",
       "   Card_Merchnum_State_total_30  Recnum  Fraud  \n",
       "0                          3.62       1      0  \n",
       "1                         31.42       2      0  \n",
       "2                        178.49       3      0  \n",
       "3                          3.62       4      0  \n",
       "4                          7.24       5      0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "vars = pd.read_csv('vars_final.csv')\n",
    "print(vars.shape)\n",
    "vars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>card_zip3_total_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>card_state_max_60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>card_state_max_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>card_merch_total_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Merchdesc_Zip_avg_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>card_zip3_total_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Merchdesc_Zip_max_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Merchnum_desc_State_avg_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Merchnum_desc_Zip_avg_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Card_Merchnum_State_total_30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  variable name\n",
       "0             card_zip3_total_7\n",
       "1             card_state_max_60\n",
       "2             card_state_max_14\n",
       "3           card_merch_total_30\n",
       "4           Merchdesc_Zip_avg_1\n",
       "5             card_zip3_total_1\n",
       "6           Merchdesc_Zip_max_1\n",
       "7     Merchnum_desc_State_avg_7\n",
       "8       Merchnum_desc_Zip_avg_7\n",
       "9  Card_Merchnum_State_total_30"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_vars = pd.read_csv('final_vars_list.csv')\n",
    "final_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Recnum',\n",
       " 'Fraud',\n",
       " 'card_zip3_total_7',\n",
       " 'card_state_max_60',\n",
       " 'card_state_max_14',\n",
       " 'card_merch_total_30',\n",
       " 'Merchdesc_Zip_avg_1',\n",
       " 'card_zip3_total_1',\n",
       " 'Merchdesc_Zip_max_1',\n",
       " 'Merchnum_desc_State_avg_7',\n",
       " 'Merchnum_desc_Zip_avg_7',\n",
       " 'Card_Merchnum_State_total_30']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.rename(columns={'recnum':'Recnum'},inplace=True)\n",
    "numvars = min(15,len(final_vars))\n",
    "final_vars_list = ['Recnum','Fraud']\n",
    "for i in range(numvars):\n",
    "    final_vars_list.append(final_vars.iloc[i]['variable name'])\n",
    "    \n",
    "final_vars_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>card_zip3_total_7</th>\n",
       "      <th>card_state_max_60</th>\n",
       "      <th>card_state_max_14</th>\n",
       "      <th>card_merch_total_30</th>\n",
       "      <th>Merchdesc_Zip_avg_1</th>\n",
       "      <th>card_zip3_total_1</th>\n",
       "      <th>Merchdesc_Zip_max_1</th>\n",
       "      <th>Merchnum_desc_State_avg_7</th>\n",
       "      <th>Merchnum_desc_Zip_avg_7</th>\n",
       "      <th>Card_Merchnum_State_total_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recnum  Fraud  card_zip3_total_7  card_state_max_60  card_state_max_14  \\\n",
       "0       1      0               3.62               3.62               3.62   \n",
       "1       2      0              31.42              31.42              31.42   \n",
       "2       3      0             178.49             178.49             178.49   \n",
       "3       4      0               3.62               3.62               3.62   \n",
       "4       5      0               7.24               3.62               3.62   \n",
       "\n",
       "   card_merch_total_30  Merchdesc_Zip_avg_1  card_zip3_total_1  \\\n",
       "0                 3.62                 3.62               3.62   \n",
       "1                31.42                31.42              31.42   \n",
       "2               178.49               178.49             178.49   \n",
       "3                 3.62                 3.62               3.62   \n",
       "4                 7.24                 3.62               7.24   \n",
       "\n",
       "   Merchdesc_Zip_max_1  Merchnum_desc_State_avg_7  Merchnum_desc_Zip_avg_7  \\\n",
       "0                 3.62                       3.62                     3.62   \n",
       "1                31.42                      31.42                    31.42   \n",
       "2               178.49                     178.49                   178.49   \n",
       "3                 3.62                       3.62                     3.62   \n",
       "4                 3.62                       3.62                     3.62   \n",
       "\n",
       "   Card_Merchnum_State_total_30  \n",
       "0                          3.62  \n",
       "1                         31.42  \n",
       "2                        178.49  \n",
       "3                          3.62  \n",
       "4                          7.24  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars = vars.filter(final_vars_list,axis=1)\n",
    "vars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96397, 12)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to cap variables. For some problems it helps\n",
    "Clip = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vars.rename(columns={'fraud_label':'Fraud'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1059"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars['Fraud'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>card_zip3_total_7</th>\n",
       "      <th>card_state_max_60</th>\n",
       "      <th>card_state_max_14</th>\n",
       "      <th>card_merch_total_30</th>\n",
       "      <th>Merchdesc_Zip_avg_1</th>\n",
       "      <th>card_zip3_total_1</th>\n",
       "      <th>Merchdesc_Zip_max_1</th>\n",
       "      <th>Merchnum_desc_State_avg_7</th>\n",
       "      <th>Merchnum_desc_Zip_avg_7</th>\n",
       "      <th>Card_Merchnum_State_total_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "      <td>31.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "      <td>178.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>7.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "      <td>230.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "      <td>62.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10.86</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>10.86</td>\n",
       "      <td>3.62</td>\n",
       "      <td>10.86</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.62</td>\n",
       "      <td>10.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recnum  Fraud  card_zip3_total_7  card_state_max_60  card_state_max_14  \\\n",
       "0       1      0               3.62               3.62               3.62   \n",
       "1       2      0              31.42              31.42              31.42   \n",
       "2       3      0             178.49             178.49             178.49   \n",
       "3       4      0               3.62               3.62               3.62   \n",
       "4       5      0               7.24               3.62               3.62   \n",
       "5       6      0               3.67               3.67               3.67   \n",
       "6       7      0               3.62               3.62               3.62   \n",
       "7       8      0             230.32             230.32             230.32   \n",
       "8       9      0              62.11              62.11              62.11   \n",
       "9      10      0              10.86               3.62               3.62   \n",
       "\n",
       "   card_merch_total_30  Merchdesc_Zip_avg_1  card_zip3_total_1  \\\n",
       "0                 3.62                 3.62               3.62   \n",
       "1                31.42                31.42              31.42   \n",
       "2               178.49               178.49             178.49   \n",
       "3                 3.62                 3.62               3.62   \n",
       "4                 7.24                 3.62               7.24   \n",
       "5                 3.67                 3.67               3.67   \n",
       "6                 3.62                 3.62               3.62   \n",
       "7               230.32               230.32             230.32   \n",
       "8                62.11                62.11              62.11   \n",
       "9                10.86                 3.62              10.86   \n",
       "\n",
       "   Merchdesc_Zip_max_1  Merchnum_desc_State_avg_7  Merchnum_desc_Zip_avg_7  \\\n",
       "0                 3.62                       3.62                     3.62   \n",
       "1                31.42                      31.42                    31.42   \n",
       "2               178.49                     178.49                   178.49   \n",
       "3                 3.62                       3.62                     3.62   \n",
       "4                 3.62                       3.62                     3.62   \n",
       "5                 3.67                       3.67                     3.67   \n",
       "6                 3.62                       3.62                     3.62   \n",
       "7               230.32                     230.32                   230.32   \n",
       "8                62.11                      62.11                    62.11   \n",
       "9                 3.62                       3.62                     3.62   \n",
       "\n",
       "   Card_Merchnum_State_total_30  \n",
       "0                          3.62  \n",
       "1                         31.42  \n",
       "2                        178.49  \n",
       "3                          3.62  \n",
       "4                          7.24  \n",
       "5                          3.67  \n",
       "6                          3.62  \n",
       "7                        230.32  \n",
       "8                         62.11  \n",
       "9                         10.86  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96397, 12)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recnum</th>\n",
       "      <th>Fraud</th>\n",
       "      <th>card_zip3_total_7</th>\n",
       "      <th>card_state_max_60</th>\n",
       "      <th>card_state_max_14</th>\n",
       "      <th>card_merch_total_30</th>\n",
       "      <th>Merchdesc_Zip_avg_1</th>\n",
       "      <th>card_zip3_total_1</th>\n",
       "      <th>Merchdesc_Zip_max_1</th>\n",
       "      <th>Merchnum_desc_State_avg_7</th>\n",
       "      <th>Merchnum_desc_Zip_avg_7</th>\n",
       "      <th>Card_Merchnum_State_total_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>48365.481820</td>\n",
       "      <td>0.010986</td>\n",
       "      <td>766.708755</td>\n",
       "      <td>826.174114</td>\n",
       "      <td>604.514604</td>\n",
       "      <td>922.819733</td>\n",
       "      <td>397.673046</td>\n",
       "      <td>620.760453</td>\n",
       "      <td>576.945176</td>\n",
       "      <td>396.373375</td>\n",
       "      <td>396.419870</td>\n",
       "      <td>922.746796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27945.003883</td>\n",
       "      <td>0.104236</td>\n",
       "      <td>4137.374620</td>\n",
       "      <td>1416.768555</td>\n",
       "      <td>1190.456997</td>\n",
       "      <td>4298.907440</td>\n",
       "      <td>751.061396</td>\n",
       "      <td>4027.918233</td>\n",
       "      <td>1162.341728</td>\n",
       "      <td>697.754300</td>\n",
       "      <td>698.229938</td>\n",
       "      <td>4298.892159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24154.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.150000</td>\n",
       "      <td>111.100000</td>\n",
       "      <td>66.960000</td>\n",
       "      <td>93.790000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>53.130000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.970000</td>\n",
       "      <td>55.890000</td>\n",
       "      <td>93.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>48365.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>238.200000</td>\n",
       "      <td>413.240000</td>\n",
       "      <td>258.250000</td>\n",
       "      <td>289.680000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>227.720000</td>\n",
       "      <td>205.438571</td>\n",
       "      <td>205.200000</td>\n",
       "      <td>289.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>72578.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>693.560000</td>\n",
       "      <td>1150.000000</td>\n",
       "      <td>734.150000</td>\n",
       "      <td>824.680000</td>\n",
       "      <td>463.460000</td>\n",
       "      <td>538.240000</td>\n",
       "      <td>695.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>824.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96753.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>28392.840000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>28392.840000</td>\n",
       "      <td>28392.840000</td>\n",
       "      <td>306633.410000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Recnum         Fraud  card_zip3_total_7  card_state_max_60  \\\n",
       "count  96397.000000  96397.000000       96397.000000       96397.000000   \n",
       "mean   48365.481820      0.010986         766.708755         826.174114   \n",
       "std    27945.003883      0.104236        4137.374620        1416.768555   \n",
       "min        1.000000      0.000000           0.010000           0.170000   \n",
       "25%    24154.000000      0.000000          77.150000         111.100000   \n",
       "50%    48365.000000      0.000000         238.200000         413.240000   \n",
       "75%    72578.000000      0.000000         693.560000        1150.000000   \n",
       "max    96753.000000      1.000000      306633.410000       47900.000000   \n",
       "\n",
       "       card_state_max_14  card_merch_total_30  Merchdesc_Zip_avg_1  \\\n",
       "count       96397.000000         96397.000000         96397.000000   \n",
       "mean          604.514604           922.819733           397.673046   \n",
       "std          1190.456997          4298.907440           751.061396   \n",
       "min             0.010000             0.010000             0.010000   \n",
       "25%            66.960000            93.790000            45.000000   \n",
       "50%           258.250000           289.680000           175.000000   \n",
       "75%           734.150000           824.680000           463.460000   \n",
       "max         47900.000000        306633.410000         28392.840000   \n",
       "\n",
       "       card_zip3_total_1  Merchdesc_Zip_max_1  Merchnum_desc_State_avg_7  \\\n",
       "count       96397.000000         96397.000000               96397.000000   \n",
       "mean          620.760453           576.945176                 396.373375   \n",
       "std          4027.918233          1162.341728                 697.754300   \n",
       "min             0.010000             0.010000                   0.010000   \n",
       "25%            53.130000            55.000000                  55.970000   \n",
       "50%           179.000000           227.720000                 205.438571   \n",
       "75%           538.240000           695.000000                 481.000000   \n",
       "max        306633.410000         47900.000000               28392.840000   \n",
       "\n",
       "       Merchnum_desc_Zip_avg_7  Card_Merchnum_State_total_30  \n",
       "count             96397.000000                  96397.000000  \n",
       "mean                396.419870                    922.746796  \n",
       "std                 698.229938                   4298.892159  \n",
       "min                   0.010000                      0.010000  \n",
       "25%                  55.890000                     93.770000  \n",
       "50%                 205.200000                    289.670000  \n",
       "75%                 481.000000                    824.580000  \n",
       "max               28392.840000                 306633.410000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fraud\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_save = vars['Recnum']\n",
    "Y_save = pd.DataFrame(vars.loc[:,'Fraud'])\n",
    "Y_save.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale and truncate field values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_zip3_total_7</th>\n",
       "      <th>card_state_max_60</th>\n",
       "      <th>card_state_max_14</th>\n",
       "      <th>card_merch_total_30</th>\n",
       "      <th>Merchdesc_Zip_avg_1</th>\n",
       "      <th>card_zip3_total_1</th>\n",
       "      <th>Merchdesc_Zip_max_1</th>\n",
       "      <th>Merchnum_desc_State_avg_7</th>\n",
       "      <th>Merchnum_desc_Zip_avg_7</th>\n",
       "      <th>Card_Merchnum_State_total_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>766.708755</td>\n",
       "      <td>826.174114</td>\n",
       "      <td>604.514604</td>\n",
       "      <td>922.819733</td>\n",
       "      <td>397.673046</td>\n",
       "      <td>620.760453</td>\n",
       "      <td>576.945176</td>\n",
       "      <td>396.373375</td>\n",
       "      <td>396.419870</td>\n",
       "      <td>922.746796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4137.374620</td>\n",
       "      <td>1416.768555</td>\n",
       "      <td>1190.456997</td>\n",
       "      <td>4298.907440</td>\n",
       "      <td>751.061396</td>\n",
       "      <td>4027.918233</td>\n",
       "      <td>1162.341728</td>\n",
       "      <td>697.754300</td>\n",
       "      <td>698.229938</td>\n",
       "      <td>4298.892159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>77.150000</td>\n",
       "      <td>111.100000</td>\n",
       "      <td>66.960000</td>\n",
       "      <td>93.790000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>53.130000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.970000</td>\n",
       "      <td>55.890000</td>\n",
       "      <td>93.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>238.200000</td>\n",
       "      <td>413.240000</td>\n",
       "      <td>258.250000</td>\n",
       "      <td>289.680000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>227.720000</td>\n",
       "      <td>205.438571</td>\n",
       "      <td>205.200000</td>\n",
       "      <td>289.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>693.560000</td>\n",
       "      <td>1150.000000</td>\n",
       "      <td>734.150000</td>\n",
       "      <td>824.680000</td>\n",
       "      <td>463.460000</td>\n",
       "      <td>538.240000</td>\n",
       "      <td>695.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>824.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>306633.410000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>28392.840000</td>\n",
       "      <td>306633.410000</td>\n",
       "      <td>47900.000000</td>\n",
       "      <td>28392.840000</td>\n",
       "      <td>28392.840000</td>\n",
       "      <td>306633.410000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       card_zip3_total_7  card_state_max_60  card_state_max_14  \\\n",
       "count       96397.000000       96397.000000       96397.000000   \n",
       "mean          766.708755         826.174114         604.514604   \n",
       "std          4137.374620        1416.768555        1190.456997   \n",
       "min             0.010000           0.170000           0.010000   \n",
       "25%            77.150000         111.100000          66.960000   \n",
       "50%           238.200000         413.240000         258.250000   \n",
       "75%           693.560000        1150.000000         734.150000   \n",
       "max        306633.410000       47900.000000       47900.000000   \n",
       "\n",
       "       card_merch_total_30  Merchdesc_Zip_avg_1  card_zip3_total_1  \\\n",
       "count         96397.000000         96397.000000       96397.000000   \n",
       "mean            922.819733           397.673046         620.760453   \n",
       "std            4298.907440           751.061396        4027.918233   \n",
       "min               0.010000             0.010000           0.010000   \n",
       "25%              93.790000            45.000000          53.130000   \n",
       "50%             289.680000           175.000000         179.000000   \n",
       "75%             824.680000           463.460000         538.240000   \n",
       "max          306633.410000         28392.840000      306633.410000   \n",
       "\n",
       "       Merchdesc_Zip_max_1  Merchnum_desc_State_avg_7  \\\n",
       "count         96397.000000               96397.000000   \n",
       "mean            576.945176                 396.373375   \n",
       "std            1162.341728                 697.754300   \n",
       "min               0.010000                   0.010000   \n",
       "25%              55.000000                  55.970000   \n",
       "50%             227.720000                 205.438571   \n",
       "75%             695.000000                 481.000000   \n",
       "max           47900.000000               28392.840000   \n",
       "\n",
       "       Merchnum_desc_Zip_avg_7  Card_Merchnum_State_total_30  \n",
       "count             96397.000000                  96397.000000  \n",
       "mean                396.419870                    922.746796  \n",
       "std                 698.229938                   4298.892159  \n",
       "min                   0.010000                      0.010000  \n",
       "25%                  55.890000                     93.770000  \n",
       "50%                 205.200000                    289.670000  \n",
       "75%                 481.000000                    824.580000  \n",
       "max               28392.840000                 306633.410000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_no_scaling = vars.drop(columns = ['Recnum','Fraud'])\n",
    "X_no_scaling.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = (X_no_scaling - X_no_scaling.mean()) / X_no_scaling.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_zip3_total_7</th>\n",
       "      <th>card_state_max_60</th>\n",
       "      <th>card_state_max_14</th>\n",
       "      <th>card_merch_total_30</th>\n",
       "      <th>Merchdesc_Zip_avg_1</th>\n",
       "      <th>card_zip3_total_1</th>\n",
       "      <th>Merchdesc_Zip_max_1</th>\n",
       "      <th>Merchnum_desc_State_avg_7</th>\n",
       "      <th>Merchnum_desc_Zip_avg_7</th>\n",
       "      <th>Card_Merchnum_State_total_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "      <td>96397.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.018605</td>\n",
       "      <td>-0.024033</td>\n",
       "      <td>-0.021577</td>\n",
       "      <td>-0.018989</td>\n",
       "      <td>-0.018710</td>\n",
       "      <td>-0.018233</td>\n",
       "      <td>-0.021442</td>\n",
       "      <td>-0.018065</td>\n",
       "      <td>-0.018062</td>\n",
       "      <td>-0.018989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.373910</td>\n",
       "      <td>0.718209</td>\n",
       "      <td>0.698488</td>\n",
       "      <td>0.432163</td>\n",
       "      <td>0.756907</td>\n",
       "      <td>0.331340</td>\n",
       "      <td>0.701772</td>\n",
       "      <td>0.757745</td>\n",
       "      <td>0.758040</td>\n",
       "      <td>0.432155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.185310</td>\n",
       "      <td>-0.583020</td>\n",
       "      <td>-0.507792</td>\n",
       "      <td>-0.214661</td>\n",
       "      <td>-0.529468</td>\n",
       "      <td>-0.154112</td>\n",
       "      <td>-0.496356</td>\n",
       "      <td>-0.568056</td>\n",
       "      <td>-0.567735</td>\n",
       "      <td>-0.214645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.166666</td>\n",
       "      <td>-0.504722</td>\n",
       "      <td>-0.451553</td>\n",
       "      <td>-0.192847</td>\n",
       "      <td>-0.469566</td>\n",
       "      <td>-0.140924</td>\n",
       "      <td>-0.449046</td>\n",
       "      <td>-0.487856</td>\n",
       "      <td>-0.487704</td>\n",
       "      <td>-0.192835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.127740</td>\n",
       "      <td>-0.291462</td>\n",
       "      <td>-0.290867</td>\n",
       "      <td>-0.147279</td>\n",
       "      <td>-0.296478</td>\n",
       "      <td>-0.109675</td>\n",
       "      <td>-0.300450</td>\n",
       "      <td>-0.273642</td>\n",
       "      <td>-0.273864</td>\n",
       "      <td>-0.147265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.017680</td>\n",
       "      <td>0.228567</td>\n",
       "      <td>0.108895</td>\n",
       "      <td>-0.022829</td>\n",
       "      <td>0.087592</td>\n",
       "      <td>-0.020487</td>\n",
       "      <td>0.101566</td>\n",
       "      <td>0.121284</td>\n",
       "      <td>0.121135</td>\n",
       "      <td>-0.022835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       card_zip3_total_7  card_state_max_60  card_state_max_14  \\\n",
       "count       96397.000000       96397.000000       96397.000000   \n",
       "mean           -0.018605          -0.024033          -0.021577   \n",
       "std             0.373910           0.718209           0.698488   \n",
       "min            -0.185310          -0.583020          -0.507792   \n",
       "25%            -0.166666          -0.504722          -0.451553   \n",
       "50%            -0.127740          -0.291462          -0.290867   \n",
       "75%            -0.017680           0.228567           0.108895   \n",
       "max             5.000000           5.000000           5.000000   \n",
       "\n",
       "       card_merch_total_30  Merchdesc_Zip_avg_1  card_zip3_total_1  \\\n",
       "count         96397.000000         96397.000000       96397.000000   \n",
       "mean             -0.018989            -0.018710          -0.018233   \n",
       "std               0.432163             0.756907           0.331340   \n",
       "min              -0.214661            -0.529468          -0.154112   \n",
       "25%              -0.192847            -0.469566          -0.140924   \n",
       "50%              -0.147279            -0.296478          -0.109675   \n",
       "75%              -0.022829             0.087592          -0.020487   \n",
       "max               5.000000             5.000000           5.000000   \n",
       "\n",
       "       Merchdesc_Zip_max_1  Merchnum_desc_State_avg_7  \\\n",
       "count         96397.000000               96397.000000   \n",
       "mean             -0.021442                  -0.018065   \n",
       "std               0.701772                   0.757745   \n",
       "min              -0.496356                  -0.568056   \n",
       "25%              -0.449046                  -0.487856   \n",
       "50%              -0.300450                  -0.273642   \n",
       "75%               0.101566                   0.121284   \n",
       "max               5.000000                   5.000000   \n",
       "\n",
       "       Merchnum_desc_Zip_avg_7  Card_Merchnum_State_total_30  \n",
       "count             96397.000000                  96397.000000  \n",
       "mean                 -0.018062                     -0.018989  \n",
       "std                   0.758040                      0.432155  \n",
       "min                  -0.567735                     -0.214645  \n",
       "25%                  -0.487704                     -0.192835  \n",
       "50%                  -0.273864                     -0.147265  \n",
       "75%                   0.121135                     -0.022835  \n",
       "max                   5.000000                      5.000000  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# push in any outlier values\n",
    "cols = X.columns\n",
    "X.loc[:,cols] = X[cols].clip(upper=Clip)\n",
    "X.loc[:,cols] = X[cols].clip(lower=-1*Clip)\n",
    "# X = (X_no_scaling - X_no_scaling.mean()) / X_no_scaling.std()\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# separate data into modeling (traintest) and out of time\n",
    "oot_recnum=84300\n",
    "X_trntst = X[0:oot_recnum]\n",
    "Y_trntst = Y_save[0:oot_recnum]\n",
    "X_oot = X[oot_recnum:]\n",
    "Y_oot = Y_save[oot_recnum:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "niter = 0\n",
    "nitermax = 10\n",
    "X_oot_orig = X_oot.copy()\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve a linear regression with ridge and lass regularization and watch how the variable weights evolve with the regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV \n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10**np.linspace(7,-2,100)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge()\n",
    "coefs = []\n",
    "for a in alphas: \n",
    "    ridge.set_params(alpha=a) \n",
    "    ridge.fit(X_trn,Y_trn.values.ravel()) \n",
    "    coefs.append(ridge.coef_) \n",
    "np.shape(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Ridge')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "ax = plt.gca() # Get the current Axes instance\n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('alpha') \n",
    "plt.ylabel('standadized coef') \n",
    "plt.title('Ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10**np.linspace(2,-8,100)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m alphas: \n\u001b[1;32m      5\u001b[0m     lasso\u001b[38;5;241m.\u001b[39mset_params(alpha\u001b[38;5;241m=\u001b[39ma) \n\u001b[0;32m----> 6\u001b[0m     \u001b[43mlasso\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_trn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_trn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      7\u001b[0m     coefs\u001b[38;5;241m.\u001b[39mappend(lasso\u001b[38;5;241m.\u001b[39mcoef_) \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# print('Shape:',np.shape(coefs)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:1054\u001b[0m, in \u001b[0;36mElasticNet.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1053\u001b[0m     this_Xy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1054\u001b[0m _, this_coef, this_dual_gap, this_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_alphas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[43malphas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mXy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthis_Xy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoef_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_n_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpositive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpositive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# from here on **params\u001b[39;49;00m\n\u001b[1;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_offset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mselection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1078\u001b[0m coef_[k] \u001b[38;5;241m=\u001b[39m this_coef[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1079\u001b[0m dual_gaps_[k] \u001b[38;5;241m=\u001b[39m this_dual_gap[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:648\u001b[0m, in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    634\u001b[0m     model \u001b[38;5;241m=\u001b[39m cd_fast\u001b[38;5;241m.\u001b[39menet_coordinate_descent_gram(\n\u001b[1;32m    635\u001b[0m         coef_,\n\u001b[1;32m    636\u001b[0m         l1_reg,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    645\u001b[0m         positive,\n\u001b[1;32m    646\u001b[0m     )\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m precompute \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 648\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mcd_fast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menet_coordinate_descent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml1_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositive\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    653\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecompute should be one of True, False, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or array-like. Got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    654\u001b[0m         \u001b[38;5;241m%\u001b[39m precompute\n\u001b[1;32m    655\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# sometimes this cell takes a long time\n",
    "lasso = Lasso(max_iter=10000) \n",
    "coefs = [] \n",
    "for a in alphas: \n",
    "    lasso.set_params(alpha=a) \n",
    "    lasso.fit(X_trn,Y_trn.values.ravel()) \n",
    "    coefs.append(lasso.coef_) \n",
    "# print('Shape:',np.shape(coefs)\n",
    "print('Selected Features:', list(vars.columns[np.where(lasso.coef_!=0)[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "ax = plt.gca() # Get the current Axes instance \n",
    "ax.plot(alphas, coefs)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('standerdized coef') \n",
    "plt.title('Lasso')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can comment out any of these model cells and just explore one model type. You can also just rerun that single cell multiple times as you explore different model hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Modeling_output = pd.DataFrame(columns=['Model','Trn','Tst','OOT'],index=range(1000))\n",
    "counter = 0\n",
    "model_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Logistic regression\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = LogisticRegression(C=1.0, solver='lbfgs', max_iter=1000)\n",
    " \n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['log reg',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Single DT\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = DecisionTreeClassifier(criterion = 'entropy', min_samples_split=1000,max_features = 10)\n",
    " \n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['DT',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "\n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# RF\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=400,max_features=10,min_samples_split=10)\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['RF',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8973561430793157 0.7974683544303798 0.5754189944134078\n",
      "1 0.8855325914149443 0.8406374501992032 0.5865921787709497\n",
      "2 0.8932676518883416 0.8413284132841329 0.5754189944134078\n",
      "3 0.8905228758169934 0.7835820895522388 0.553072625698324\n",
      "4 0.8938640132669984 0.8158844765342961 0.5754189944134078\n",
      "5 0.8915094339622641 0.8155737704918032 0.5586592178770949\n",
      "6 0.8924558587479936 0.8443579766536965 0.547486033519553\n",
      "7 0.8914473684210527 0.8345588235294118 0.5754189944134078\n",
      "8 0.8890675241157556 0.8410852713178295 0.5698324022346368\n",
      "9 0.8828250401284109 0.8210116731517509 0.5418994413407822\n",
      "trn    0.890785\n",
      "tst    0.823549\n",
      "oot    0.565922\n",
      "dtype: float64\n",
      "CPU times: user 38.2 s, sys: 9.84 s, total: 48.1 s\n",
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# LGBM\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = lgb.LGBMClassifier(n_estimators = 60, num_leaves=40, max_depth = 10, learning_rate=0.01)\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter,'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "#good\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter,'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter,'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['LGBM',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# NN\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):  \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = MLPClassifier(max_iter=1000, hidden_layer_sizes=(100,),activation='relu',solver='sgd',\n",
    "                          learning_rate='adaptive',learning_rate_init=.001)\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['NN',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# GBC\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):  \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = GradientBoostingClassifier(n_estimators=400, learning_rate=0.1, max_features = 10,\n",
    "                                      min_samples_split = 10)\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['GBC',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Catboost\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):  \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = CatBoostClassifier(verbose=0,\n",
    "            iterations=100,\n",
    "#             learning_rate=0.03,\n",
    "#             l2_leaf_reg=5\n",
    "    \n",
    "    )\n",
    "#\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['cat boost',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # XGB\n",
    "\n",
    "# FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "# for niter in range(nitermax):  \n",
    "#     X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "#     model = XGBClassifier(\n",
    "#         booster='gbtree',\n",
    "#         max_depth=5, \n",
    "#         min_child_weight=75,\n",
    "#         sub_sample=75,\n",
    "#         gamma=0.01, \n",
    "#     )\n",
    "\n",
    "#     X_oot = X_oot_orig.copy()\n",
    "#     X_trn_save = X_trn.copy()\n",
    "#     Y_trn_save = Y_trn.copy()\n",
    "\n",
    "#     model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "#     predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "#     X_trn['predicted'] = predictions\n",
    "#     X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "#     topRows = int(round(X_trn.shape[0]*0.03))\n",
    "#     temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_tst)[:,1]\n",
    "#     X_tst['predicted']=predictions\n",
    "#     X_tst['Fraud'] = Y_tst['Fraud']\n",
    "#     topRows = int(round(X_tst.shape[0]*0.03))\n",
    "#     temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_oot)[:,1]\n",
    "#     X_oot['predicted']=predictions\n",
    "#     X_oot['Fraud'] = Y_oot['Fraud']\n",
    "#     topRows = int(round(X_oot.shape[0]*0.03))\n",
    "#     temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "#     print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "#     Modeling_output.iloc[counter] = ['XGB',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "#     counter = counter + 1\n",
    "    \n",
    "# print(FDR3.mean())\n",
    "# model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Knn\n",
    "\n",
    "FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "for niter in range(nitermax):  \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "    model = KNeighborsClassifier(n_neighbors=300) \n",
    "    \n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['Knn',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # SVM\n",
    "\n",
    "# FDR3 = pd.DataFrame(np.zeros((nitermax,3)), columns=('trn', 'tst', 'oot'))\n",
    "# for niter in range(nitermax):  \n",
    "#     X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "#     model = svm.SVC(\n",
    "#         C=.1, \n",
    "# #         gamma=100,\n",
    "# #         kernel='linear',\n",
    "#         kernel='poly',\n",
    "#         probability=True)\n",
    "    \n",
    "#     X_oot = X_oot_orig.copy()\n",
    "#     X_trn_save = X_trn.copy()\n",
    "#     Y_trn_save = Y_trn.copy()\n",
    "\n",
    "#     model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "#     predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "#     X_trn['predicted'] = predictions\n",
    "#     X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "#     topRows = int(round(X_trn.shape[0]*0.03))\n",
    "#     temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_tst)[:,1]\n",
    "#     X_tst['predicted']=predictions\n",
    "#     X_tst['Fraud'] = Y_tst['Fraud']\n",
    "#     topRows = int(round(X_tst.shape[0]*0.03))\n",
    "#     temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "#     predictions = model.predict_proba(X_oot)[:,1]\n",
    "#     X_oot['predicted']=predictions\n",
    "#     X_oot['Fraud'] = Y_oot['Fraud']\n",
    "#     topRows = int(round(X_oot.shape[0]*0.03))\n",
    "#     temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "#     needed = temp.loc[:,'Fraud']\n",
    "#     FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "#     print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "#     Modeling_output.iloc[counter] = ['SVM',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "#     counter = counter + 1\n",
    "    \n",
    "# print(FDR3.mean())\n",
    "# model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Trn</th>\n",
       "      <th>Tst</th>\n",
       "      <th>OOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.897356</td>\n",
       "      <td>0.797468</td>\n",
       "      <td>0.575419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.885533</td>\n",
       "      <td>0.840637</td>\n",
       "      <td>0.586592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.893268</td>\n",
       "      <td>0.841328</td>\n",
       "      <td>0.575419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.890523</td>\n",
       "      <td>0.783582</td>\n",
       "      <td>0.553073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.893864</td>\n",
       "      <td>0.815884</td>\n",
       "      <td>0.575419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model       Trn       Tst       OOT\n",
       "0  LGBM  0.897356  0.797468  0.575419\n",
       "1  LGBM  0.885533  0.840637  0.586592\n",
       "2  LGBM  0.893268  0.841328  0.575419\n",
       "3  LGBM  0.890523  0.783582  0.553073\n",
       "4  LGBM  0.893864  0.815884  0.575419"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = Modeling_output.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.897356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.885533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.893268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.890523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.893864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Type     Value\n",
       "0  LGBM  Trn  0.897356\n",
       "1  LGBM  Trn  0.885533\n",
       "2  LGBM  Trn  0.893268\n",
       "3  LGBM  Trn  0.890523\n",
       "4  LGBM  Trn  0.893864"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unpivot = df.melt( id_vars='Model', value_vars=['Trn','Tst','OOT'], var_name=['Type'], value_name='Value')\n",
    "df_unpivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.897356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.885533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.893268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.890523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>Trn</td>\n",
       "      <td>0.893864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Type     Value\n",
       "0  LGBM  Trn  0.897356\n",
       "1  LGBM  Trn  0.885533\n",
       "2  LGBM  Trn  0.893268\n",
       "3  LGBM  Trn  0.890523\n",
       "4  LGBM  Trn  0.893864"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare = df_unpivot[(df_unpivot['Type']=='Trn') | (df_unpivot['Type']=='Tst') | (df_unpivot['Type']=='OOT')]\n",
    "df_compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Trn</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Tst</th>\n",
       "      <th colspan=\"2\" halign=\"left\">OOT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBM</th>\n",
       "      <td>0.890785</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.823549</td>\n",
       "      <td>0.020753</td>\n",
       "      <td>0.565922</td>\n",
       "      <td>0.014675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Trn                 Tst                 OOT          \n",
       "           mean       std      mean       std      mean       std\n",
       "Model                                                            \n",
       "LGBM   0.890785  0.004171  0.823549  0.020753  0.565922  0.014675"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = df.groupby('Model').agg({'Trn':['mean','std'],'Tst':['mean','std'],'OOT':['mean','std']})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(20,15))\n",
    "# plt.rcParams.update({'font.size':20})\n",
    "# ax = sns.boxplot(x='Model',y='Trn', data=df, color='navy')\n",
    "\n",
    "# # Select which box you want to change    \n",
    "# mybox = ax.artists[model_counter-1]\n",
    "\n",
    "# # Change the appearance of that box\n",
    "# mybox.set_facecolor('red')\n",
    "# # mybox.set_edgecolor('black')\n",
    "# # mybox.set_linewidth(3)\n",
    "# plt.ylim(0,1)\n",
    "# plt.xlabel('')\n",
    "# plt.ylabel('Train Score (FDR3%)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(20,15))\n",
    "# ax = sns.boxplot(x='Model',y='Tst', data=df, color='navy')\n",
    "\n",
    "# # Select which box you want to change    \n",
    "# mybox = ax.artists[model_counter-1]\n",
    "\n",
    "# # Change the appearance of that box\n",
    "# mybox.set_facecolor('red')\n",
    "# # mybox.set_edgecolor('black')\n",
    "# # mybox.set_linewidth(3)\n",
    "# plt.ylim(0,1)\n",
    "# plt.xlabel('')\n",
    "# plt.ylabel('Test Score (FDR3%)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(20,15))\n",
    "# ax = sns.boxplot(x='Model',y='OOT', data=df, color='navy')\n",
    "\n",
    "# # Select which box you want to change    \n",
    "# mybox = ax.artists[model_counter-1]\n",
    "\n",
    "# # Change the appearance of that box\n",
    "# mybox.set_facecolor('red')\n",
    "# # mybox.set_edgecolor('black')\n",
    "# # mybox.set_linewidth(3)\n",
    "# plt.ylim(0,1)\n",
    "# plt.xlabel('')\n",
    "# plt.ylabel('OOT Score (FDR3%)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,15))\n",
    "# ax = sns.boxplot(x='Model',y='OOT', data=df, color='navy')\n",
    "ax = sns.boxplot(x='Model',y='Value',hue='Type', data=df_compare, palette=['navy','r','g'])\n",
    "# Select which box you want to change    \n",
    "mybox = ax.artists[model_counter-1]\n",
    "\n",
    "# Change the appearance of that box\n",
    "mybox.set_edgecolor('black')\n",
    "# mybox.set_linewidth(3)\n",
    "# plxlabelabel('')\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel('Score (FDR3%)')\n",
    "plt.yticks(np.arange(0,1,.1))\n",
    "plt.grid(axis='y')\n",
    "plt.savefig('modeling.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration:  0:00:37.183895\n"
     ]
    }
   ],
   "source": [
    "print('duration: ', datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the notebook makes the tables for your final model of choice. You need to run that final model only once (no CV). If you want you can run the below cell over and over by itself until it gives you a model you like. But you can't change from your best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7983193277310925 0.8105263157894737 0.5698324022346368\n",
      "trn    0.880881\n",
      "tst    0.824855\n",
      "oot    0.565363\n",
      "dtype: float64\n",
      "CPU times: user 992 ms, sys: 196 ms, total: 1.19 s\n",
      "Wall time: 197 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for niter in range(30):    \n",
    "    X_trn, X_tst, Y_trn, Y_tst = train_test_split(X_trntst, Y_trntst, test_size = .3)\n",
    "\n",
    "# here's where you put your final model of choice\n",
    "    model = lgb.LGBMClassifier(num_leaves=3,n_estimators=50)\n",
    "\n",
    "    X_oot = X_oot_orig.copy()\n",
    "    X_trn_save = X_trn.copy()\n",
    "    Y_trn_save = Y_trn.copy()\n",
    "\n",
    "    model.fit(X_trn, Y_trn.values.ravel())   \n",
    "\n",
    "    predictions = model.predict_proba(X_trn_save)[:,1]\n",
    "    X_trn['predicted'] = predictions\n",
    "    X_trn['Fraud'] = Y_trn_save['Fraud']\n",
    "    topRows = int(round(X_trn.shape[0]*0.03))\n",
    "    temp = X_trn.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'trn'] = sum(needed)/sum(X_trn.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_tst)[:,1]\n",
    "    X_tst['predicted']=predictions\n",
    "    X_tst['Fraud'] = Y_tst['Fraud']\n",
    "    topRows = int(round(X_tst.shape[0]*0.03))\n",
    "    temp = X_tst.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'tst'] = sum(needed)/sum(X_tst.loc[:,'Fraud'])\n",
    "\n",
    "    predictions = model.predict_proba(X_oot)[:,1]\n",
    "    X_oot['predicted']=predictions\n",
    "    X_oot['Fraud'] = Y_oot['Fraud']\n",
    "    topRows = int(round(X_oot.shape[0]*0.03))\n",
    "    temp = X_oot.sort_values('predicted',ascending=False).head(topRows)\n",
    "    needed = temp.loc[:,'Fraud']\n",
    "    FDR3.loc[niter, 'oot'] = sum(needed)/sum(X_oot.loc[:,'Fraud'])\n",
    "    print(niter, FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot'])\n",
    "    Modeling_output.iloc[counter] = ['LGBM',FDR3.loc[niter, 'trn'],FDR3.loc[niter, 'tst'],FDR3.loc[niter, 'oot']]\n",
    "    counter = counter + 1\n",
    "    if(FDR3.loc[niter, 'oot'] > .56): break\n",
    "    \n",
    "print(FDR3.mean())\n",
    "model_counter = model_counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn_eval = X_trn.copy()\n",
    "X_tst_eval = X_tst.copy()\n",
    "X_oot_eval = X_oot.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_zip3_total_7</th>\n",
       "      <th>card_state_max_60</th>\n",
       "      <th>card_state_max_14</th>\n",
       "      <th>card_merch_total_30</th>\n",
       "      <th>Merchdesc_Zip_avg_1</th>\n",
       "      <th>card_zip3_total_1</th>\n",
       "      <th>Merchdesc_Zip_max_1</th>\n",
       "      <th>Merchnum_desc_State_avg_7</th>\n",
       "      <th>Merchnum_desc_Zip_avg_7</th>\n",
       "      <th>Card_Merchnum_State_total_30</th>\n",
       "      <th>predicted</th>\n",
       "      <th>Fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89128</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.971886</td>\n",
       "      <td>2.532948</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.122218</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.617935</td>\n",
       "      <td>1.209816</td>\n",
       "      <td>1.208926</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.680467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89117</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.971886</td>\n",
       "      <td>2.532948</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.220710</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.617935</td>\n",
       "      <td>1.315833</td>\n",
       "      <td>1.314870</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.680467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89083</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.971886</td>\n",
       "      <td>2.532948</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.231018</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.617935</td>\n",
       "      <td>1.326928</td>\n",
       "      <td>1.325958</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.680467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89121</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.971886</td>\n",
       "      <td>2.532948</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.176295</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.617935</td>\n",
       "      <td>1.268024</td>\n",
       "      <td>1.267094</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.680467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89082</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.971886</td>\n",
       "      <td>2.532948</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.320430</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.617935</td>\n",
       "      <td>1.423171</td>\n",
       "      <td>1.422135</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.680467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89077</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.971886</td>\n",
       "      <td>2.532948</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.442587</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.617935</td>\n",
       "      <td>1.554661</td>\n",
       "      <td>1.553535</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.680467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89074</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.971886</td>\n",
       "      <td>2.532948</td>\n",
       "      <td>4.818969</td>\n",
       "      <td>1.548340</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.617935</td>\n",
       "      <td>1.668493</td>\n",
       "      <td>1.667290</td>\n",
       "      <td>4.819003</td>\n",
       "      <td>0.680467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89068</th>\n",
       "      <td>4.327532</td>\n",
       "      <td>1.971886</td>\n",
       "      <td>2.532948</td>\n",
       "      <td>4.128610</td>\n",
       "      <td>1.378009</td>\n",
       "      <td>4.481364</td>\n",
       "      <td>2.617935</td>\n",
       "      <td>1.485149</td>\n",
       "      <td>1.484071</td>\n",
       "      <td>4.128641</td>\n",
       "      <td>0.680467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89114</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.971886</td>\n",
       "      <td>2.532948</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.295685</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.617935</td>\n",
       "      <td>1.396535</td>\n",
       "      <td>1.395517</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.680467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89120</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.971886</td>\n",
       "      <td>2.532948</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.149713</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.617935</td>\n",
       "      <td>1.239411</td>\n",
       "      <td>1.238500</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.680467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89112</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.971886</td>\n",
       "      <td>2.532948</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.745219</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.714269</td>\n",
       "      <td>-0.090626</td>\n",
       "      <td>-0.090631</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.677146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89091</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.971886</td>\n",
       "      <td>2.532948</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.908294</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.714269</td>\n",
       "      <td>-0.103460</td>\n",
       "      <td>-0.103456</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.677146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93137</th>\n",
       "      <td>1.061502</td>\n",
       "      <td>3.057921</td>\n",
       "      <td>3.825443</td>\n",
       "      <td>0.985302</td>\n",
       "      <td>1.253196</td>\n",
       "      <td>1.126582</td>\n",
       "      <td>3.941693</td>\n",
       "      <td>0.312368</td>\n",
       "      <td>0.312088</td>\n",
       "      <td>0.985322</td>\n",
       "      <td>0.631275</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89129</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.971886</td>\n",
       "      <td>2.532948</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.043068</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-0.080007</td>\n",
       "      <td>0.048221</td>\n",
       "      <td>0.048122</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.616718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89049</th>\n",
       "      <td>2.693936</td>\n",
       "      <td>1.971886</td>\n",
       "      <td>2.532948</td>\n",
       "      <td>2.556396</td>\n",
       "      <td>1.182433</td>\n",
       "      <td>2.803376</td>\n",
       "      <td>2.617935</td>\n",
       "      <td>1.274631</td>\n",
       "      <td>1.273696</td>\n",
       "      <td>2.556422</td>\n",
       "      <td>0.614837</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89055</th>\n",
       "      <td>2.977229</td>\n",
       "      <td>1.971886</td>\n",
       "      <td>2.532948</td>\n",
       "      <td>2.829044</td>\n",
       "      <td>1.163516</td>\n",
       "      <td>3.094368</td>\n",
       "      <td>2.617935</td>\n",
       "      <td>1.254269</td>\n",
       "      <td>1.253348</td>\n",
       "      <td>2.829071</td>\n",
       "      <td>0.614837</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89057</th>\n",
       "      <td>3.338956</td>\n",
       "      <td>1.971886</td>\n",
       "      <td>2.532948</td>\n",
       "      <td>3.177179</td>\n",
       "      <td>1.196810</td>\n",
       "      <td>3.465924</td>\n",
       "      <td>2.617935</td>\n",
       "      <td>1.290107</td>\n",
       "      <td>1.289162</td>\n",
       "      <td>3.177208</td>\n",
       "      <td>0.614837</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89060</th>\n",
       "      <td>3.565150</td>\n",
       "      <td>1.971886</td>\n",
       "      <td>2.532948</td>\n",
       "      <td>3.394874</td>\n",
       "      <td>1.148785</td>\n",
       "      <td>3.698265</td>\n",
       "      <td>2.617935</td>\n",
       "      <td>1.238412</td>\n",
       "      <td>1.237502</td>\n",
       "      <td>3.394903</td>\n",
       "      <td>0.614837</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95189</th>\n",
       "      <td>3.988590</td>\n",
       "      <td>3.860776</td>\n",
       "      <td>4.780925</td>\n",
       "      <td>2.714453</td>\n",
       "      <td>2.628335</td>\n",
       "      <td>2.972066</td>\n",
       "      <td>4.920287</td>\n",
       "      <td>4.997284</td>\n",
       "      <td>4.993814</td>\n",
       "      <td>2.714479</td>\n",
       "      <td>0.586357</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89075</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.971886</td>\n",
       "      <td>2.532948</td>\n",
       "      <td>4.931544</td>\n",
       "      <td>0.114873</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-0.080007</td>\n",
       "      <td>0.125512</td>\n",
       "      <td>0.125360</td>\n",
       "      <td>4.931578</td>\n",
       "      <td>0.576473</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       card_zip3_total_7  card_state_max_60  card_state_max_14  \\\n",
       "89128           5.000000           1.971886           2.532948   \n",
       "89117           5.000000           1.971886           2.532948   \n",
       "89083           5.000000           1.971886           2.532948   \n",
       "89121           5.000000           1.971886           2.532948   \n",
       "89082           5.000000           1.971886           2.532948   \n",
       "89077           5.000000           1.971886           2.532948   \n",
       "89074           5.000000           1.971886           2.532948   \n",
       "89068           4.327532           1.971886           2.532948   \n",
       "89114           5.000000           1.971886           2.532948   \n",
       "89120           5.000000           1.971886           2.532948   \n",
       "89112           5.000000           1.971886           2.532948   \n",
       "89091           5.000000           1.971886           2.532948   \n",
       "93137           1.061502           3.057921           3.825443   \n",
       "89129           5.000000           1.971886           2.532948   \n",
       "89049           2.693936           1.971886           2.532948   \n",
       "89055           2.977229           1.971886           2.532948   \n",
       "89057           3.338956           1.971886           2.532948   \n",
       "89060           3.565150           1.971886           2.532948   \n",
       "95189           3.988590           3.860776           4.780925   \n",
       "89075           5.000000           1.971886           2.532948   \n",
       "\n",
       "       card_merch_total_30  Merchdesc_Zip_avg_1  card_zip3_total_1  \\\n",
       "89128             5.000000             1.122218           5.000000   \n",
       "89117             5.000000             1.220710           5.000000   \n",
       "89083             5.000000             1.231018           5.000000   \n",
       "89121             5.000000             1.176295           5.000000   \n",
       "89082             5.000000             1.320430           5.000000   \n",
       "89077             5.000000             1.442587           5.000000   \n",
       "89074             4.818969             1.548340           5.000000   \n",
       "89068             4.128610             1.378009           4.481364   \n",
       "89114             5.000000             1.295685           5.000000   \n",
       "89120             5.000000             1.149713           5.000000   \n",
       "89112             5.000000             0.745219           5.000000   \n",
       "89091             5.000000             0.908294           5.000000   \n",
       "93137             0.985302             1.253196           1.126582   \n",
       "89129             5.000000             0.043068           5.000000   \n",
       "89049             2.556396             1.182433           2.803376   \n",
       "89055             2.829044             1.163516           3.094368   \n",
       "89057             3.177179             1.196810           3.465924   \n",
       "89060             3.394874             1.148785           3.698265   \n",
       "95189             2.714453             2.628335           2.972066   \n",
       "89075             4.931544             0.114873           5.000000   \n",
       "\n",
       "       Merchdesc_Zip_max_1  Merchnum_desc_State_avg_7  \\\n",
       "89128             2.617935                   1.209816   \n",
       "89117             2.617935                   1.315833   \n",
       "89083             2.617935                   1.326928   \n",
       "89121             2.617935                   1.268024   \n",
       "89082             2.617935                   1.423171   \n",
       "89077             2.617935                   1.554661   \n",
       "89074             2.617935                   1.668493   \n",
       "89068             2.617935                   1.485149   \n",
       "89114             2.617935                   1.396535   \n",
       "89120             2.617935                   1.239411   \n",
       "89112             0.714269                  -0.090626   \n",
       "89091             0.714269                  -0.103460   \n",
       "93137             3.941693                   0.312368   \n",
       "89129            -0.080007                   0.048221   \n",
       "89049             2.617935                   1.274631   \n",
       "89055             2.617935                   1.254269   \n",
       "89057             2.617935                   1.290107   \n",
       "89060             2.617935                   1.238412   \n",
       "95189             4.920287                   4.997284   \n",
       "89075            -0.080007                   0.125512   \n",
       "\n",
       "       Merchnum_desc_Zip_avg_7  Card_Merchnum_State_total_30  predicted  Fraud  \n",
       "89128                 1.208926                      5.000000   0.680467      1  \n",
       "89117                 1.314870                      5.000000   0.680467      1  \n",
       "89083                 1.325958                      5.000000   0.680467      1  \n",
       "89121                 1.267094                      5.000000   0.680467      1  \n",
       "89082                 1.422135                      5.000000   0.680467      1  \n",
       "89077                 1.553535                      5.000000   0.680467      1  \n",
       "89074                 1.667290                      4.819003   0.680467      1  \n",
       "89068                 1.484071                      4.128641   0.680467      1  \n",
       "89114                 1.395517                      5.000000   0.680467      1  \n",
       "89120                 1.238500                      5.000000   0.680467      1  \n",
       "89112                -0.090631                      5.000000   0.677146      1  \n",
       "89091                -0.103456                      5.000000   0.677146      1  \n",
       "93137                 0.312088                      0.985322   0.631275      1  \n",
       "89129                 0.048122                      5.000000   0.616718      1  \n",
       "89049                 1.273696                      2.556422   0.614837      1  \n",
       "89055                 1.253348                      2.829071   0.614837      1  \n",
       "89057                 1.289162                      3.177208   0.614837      1  \n",
       "89060                 1.237502                      3.394903   0.614837      1  \n",
       "95189                 4.993814                      2.714479   0.586357      0  \n",
       "89075                 0.125360                      4.931578   0.576473      1  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['bin','#recs','#g','#b','%g','%b','tot','cg','cb','%cg','FDR','KS','FPR']\n",
    "FDR_trn = pd.DataFrame(np.zeros((101, 13)), columns = cols)\n",
    "FDR_tst = pd.DataFrame(np.zeros((101, 13)), columns = cols)\n",
    "FDR_oot = pd.DataFrame(np.zeros((101, 13)), columns = cols)\n",
    "trn_sorted = X_trn_eval.sort_values('predicted',ascending=False)\n",
    "tst_sorted = X_tst_eval.sort_values('predicted',ascending=False)\n",
    "oot_sorted = X_oot_eval.sort_values('predicted',ascending=False)\n",
    "bad_tot_trn = sum(X_trn_eval.loc[:, 'Fraud'])\n",
    "bad_tot_tst = sum(X_tst_eval.loc[:, 'Fraud'])\n",
    "bad_tot_oot = sum(X_oot_eval.loc[:, 'Fraud'])\n",
    "num_tot_trn = len(X_trn_eval)\n",
    "num_tot_tst = len(X_tst_eval)\n",
    "num_tot_oot = len(X_oot_eval)\n",
    "good_tot_trn = num_tot_trn - bad_tot_trn\n",
    "good_tot_tst = num_tot_tst - bad_tot_tst\n",
    "good_tot_oot = num_tot_oot - bad_tot_oot\n",
    "oot_sorted.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin</th>\n",
       "      <th>#recs</th>\n",
       "      <th>#g</th>\n",
       "      <th>#b</th>\n",
       "      <th>%g</th>\n",
       "      <th>%b</th>\n",
       "      <th>tot</th>\n",
       "      <th>cg</th>\n",
       "      <th>cb</th>\n",
       "      <th>%cg</th>\n",
       "      <th>FDR</th>\n",
       "      <th>KS</th>\n",
       "      <th>FPR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>53.719008</td>\n",
       "      <td>46.280992</td>\n",
       "      <td>121.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.545394</td>\n",
       "      <td>31.284916</td>\n",
       "      <td>30.739523</td>\n",
       "      <td>1.160714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>76.033058</td>\n",
       "      <td>23.966942</td>\n",
       "      <td>242.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.317335</td>\n",
       "      <td>47.486034</td>\n",
       "      <td>46.168698</td>\n",
       "      <td>1.847059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>85.950413</td>\n",
       "      <td>14.049587</td>\n",
       "      <td>363.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>2.189965</td>\n",
       "      <td>56.983240</td>\n",
       "      <td>54.793275</td>\n",
       "      <td>2.558824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>96.694215</td>\n",
       "      <td>3.305785</td>\n",
       "      <td>484.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>3.171673</td>\n",
       "      <td>59.217877</td>\n",
       "      <td>56.046204</td>\n",
       "      <td>3.566038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11613.0</td>\n",
       "      <td>11434.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>95.938916</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4.061084</td>\n",
       "      <td>63.877095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11734.0</td>\n",
       "      <td>11555.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>96.954187</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3.045813</td>\n",
       "      <td>64.553073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11855.0</td>\n",
       "      <td>11676.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>97.969458</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2.030542</td>\n",
       "      <td>65.229050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11976.0</td>\n",
       "      <td>11797.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>98.984729</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.015271</td>\n",
       "      <td>65.905028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12097.0</td>\n",
       "      <td>11918.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.581006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bin  #recs     #g    #b          %g         %b      tot       cg  \\\n",
       "0      0.0    0.0    0.0   0.0    0.000000   0.000000      0.0      0.0   \n",
       "1      1.0  121.0   65.0  56.0   53.719008  46.280992    121.0     65.0   \n",
       "2      2.0  121.0   92.0  29.0   76.033058  23.966942    242.0    157.0   \n",
       "3      3.0  121.0  104.0  17.0   85.950413  14.049587    363.0    261.0   \n",
       "4      4.0  121.0  117.0   4.0   96.694215   3.305785    484.0    378.0   \n",
       "..     ...    ...    ...   ...         ...        ...      ...      ...   \n",
       "96    96.0  121.0  121.0   0.0  100.000000   0.000000  11613.0  11434.0   \n",
       "97    97.0  121.0  121.0   0.0  100.000000   0.000000  11734.0  11555.0   \n",
       "98    98.0  121.0  121.0   0.0  100.000000   0.000000  11855.0  11676.0   \n",
       "99    99.0  121.0  121.0   0.0  100.000000   0.000000  11976.0  11797.0   \n",
       "100  100.0  121.0  121.0   0.0  100.000000   0.000000  12097.0  11918.0   \n",
       "\n",
       "        cb         %cg         FDR         KS        FPR  \n",
       "0      0.0    0.000000    0.000000   0.000000   0.000000  \n",
       "1     56.0    0.545394   31.284916  30.739523   1.160714  \n",
       "2     85.0    1.317335   47.486034  46.168698   1.847059  \n",
       "3    102.0    2.189965   56.983240  54.793275   2.558824  \n",
       "4    106.0    3.171673   59.217877  56.046204   3.566038  \n",
       "..     ...         ...         ...        ...        ...  \n",
       "96   179.0   95.938916  100.000000   4.061084  63.877095  \n",
       "97   179.0   96.954187  100.000000   3.045813  64.553073  \n",
       "98   179.0   97.969458  100.000000   2.030542  65.229050  \n",
       "99   179.0   98.984729  100.000000   1.015271  65.905028  \n",
       "100  179.0  100.000000  100.000000   0.000000  66.581006  \n",
       "\n",
       "[101 rows x 13 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(101):\n",
    "    percent_rows_trn = int(round(X_trn_eval.shape[0]*0.01*i))\n",
    "    percent_rows_tst = int(round(X_tst_eval.shape[0]*0.01*i))\n",
    "    percent_rows_oot = int(round(X_oot_eval.shape[0]*0.01*i))\n",
    "    temp_trn = trn_sorted.head(percent_rows_trn)\n",
    "    temp_tst = tst_sorted.head(percent_rows_tst)\n",
    "    temp_oot = oot_sorted.head(percent_rows_oot)\n",
    "    num_bad_trn = sum(temp_trn.loc[:,'Fraud'])\n",
    "    num_bad_tst = sum(temp_tst.loc[:,'Fraud'])\n",
    "    num_bad_oot = sum(temp_oot.loc[:,'Fraud'])\n",
    "    num_tot_trn = len(temp_trn)\n",
    "    num_tot_tst = len(temp_tst)\n",
    "    num_tot_oot = len(temp_oot)\n",
    "    num_good_trn = num_tot_trn - num_bad_trn\n",
    "    num_good_tst = num_tot_tst - num_bad_tst\n",
    "    num_good_oot = num_tot_oot - num_bad_oot\n",
    "    \n",
    "    FDR_trn.loc[i, 'bin'] = i\n",
    "    FDR_trn.loc[i,'#recs'] = 0\n",
    "    FDR_trn.loc[i, 'tot'] = num_tot_trn\n",
    "    FDR_trn.loc[i, 'cg'] = num_good_trn\n",
    "    FDR_trn.loc[i, 'cb'] = num_bad_trn\n",
    "    FDR_tst.loc[i, 'bin'] = i\n",
    "    FDR_tst.loc[i, 'tot'] = num_tot_tst\n",
    "    FDR_tst.loc[i, 'cg'] = num_good_tst\n",
    "    FDR_tst.loc[i, 'cb'] = num_bad_tst\n",
    "    FDR_oot.loc[i, 'bin'] = i\n",
    "    FDR_oot.loc[i, 'tot'] = num_tot_oot\n",
    "    FDR_oot.loc[i, 'cg'] = num_good_oot\n",
    "    FDR_oot.loc[i, 'cb'] = num_bad_oot\n",
    "    if i != 0:\n",
    "        FDR_trn.loc[i, '#g'] = num_good_trn - FDR_trn.loc[i-1, 'cg']\n",
    "        FDR_trn.loc[i, '#b'] = num_bad_trn - FDR_trn.loc[i-1, 'cb']\n",
    "        FDR_trn.loc[i,'#recs'] = FDR_trn.loc[i, '#g'] + FDR_trn.loc[i, '#b']\n",
    "        FDR_trn.loc[i, '%g'] = 100* (num_good_trn - FDR_trn.loc[i-1, 'cg']) / (num_tot_trn - FDR_trn.loc[i-1, 'tot'])\n",
    "        FDR_trn.loc[i, '%b'] = 100 - FDR_trn.loc[i, '%g']\n",
    "        FDR_trn.loc[i, '%cg'] = 100 * num_good_trn / good_tot_trn\n",
    "        FDR_trn.loc[i, 'FDR'] = 100 * num_bad_trn / bad_tot_trn\n",
    "        FDR_trn.loc[i, 'KS'] = FDR_trn.loc[i, 'FDR'] - FDR_trn.loc[i, '%cg']\n",
    "        FDR_trn.loc[i, 'FPR'] = num_good_trn / num_bad_trn\n",
    "        FDR_tst.loc[i, '#g'] = num_good_tst - FDR_tst.loc[i-1, 'cg']\n",
    "        FDR_tst.loc[i, '#b'] = num_bad_tst - FDR_tst.loc[i-1, 'cb']\n",
    "        FDR_tst.loc[i,'#recs'] = FDR_tst.loc[i, '#g'] + FDR_tst.loc[i, '#b']\n",
    "        FDR_tst.loc[i, '%g'] = 100* (num_good_tst - FDR_tst.loc[i-1, 'cg']) / (num_tot_tst - FDR_tst.loc[i-1, 'tot'])\n",
    "        FDR_tst.loc[i, '%b'] = 100 - FDR_tst.loc[i, '%g']\n",
    "        FDR_tst.loc[i, '%cg'] = 100 * num_good_tst / good_tot_tst\n",
    "        FDR_tst.loc[i, 'FDR'] = 100 * num_bad_tst / bad_tot_tst\n",
    "        FDR_tst.loc[i, 'KS'] = FDR_tst.loc[i, 'FDR'] - FDR_tst.loc[i, '%cg']\n",
    "        FDR_tst.loc[i, 'FPR'] = num_good_tst / num_bad_tst\n",
    "        FDR_oot.loc[i, '#g'] = num_good_oot - FDR_oot.loc[i-1, 'cg']\n",
    "        FDR_oot.loc[i, '#b'] = num_bad_oot - FDR_oot.loc[i-1, 'cb']\n",
    "        FDR_oot.loc[i,'#recs'] = FDR_oot.loc[i, '#g'] + FDR_oot.loc[i, '#b']\n",
    "        FDR_oot.loc[i, '%g'] = 100* (num_good_oot - FDR_oot.loc[i-1, 'cg']) / (num_tot_oot - FDR_oot.loc[i-1, 'tot'])\n",
    "        FDR_oot.loc[i, '%b'] = 100 - FDR_oot.loc[i, '%g']\n",
    "        FDR_oot.loc[i, '%cg'] = 100 * num_good_oot / good_tot_oot\n",
    "        FDR_oot.loc[i, 'FDR'] = 100 * num_bad_oot / bad_tot_oot\n",
    "        FDR_oot.loc[i, 'KS'] = FDR_oot.loc[i, 'FDR'] - FDR_oot.loc[i, '%cg']\n",
    "        FDR_oot.loc[i, 'FPR'] = num_good_oot / num_bad_oot\n",
    "\n",
    "FDR_oot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR3.to_csv('FDR3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDR_trn.to_csv('FDR_trn.csv', index=False)\n",
    "FDR_tst.to_csv('FDR_tst.csv', index=False)\n",
    "FDR_oot.to_csv('FDR_oot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duration:  0:00:43.256383\n"
     ]
    }
   ],
   "source": [
    "print(\"duration: \", datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12097"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oot_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oot_sorted[oot_sorted['Fraud'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11918"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oot_sorted) - len(oot_sorted[oot_sorted['Fraud'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
